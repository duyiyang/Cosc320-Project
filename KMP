import os
import re
import timeit
import matplotlib.pyplot as plt





def preprocess(text):
    text = re.sub(r'\W+', ' ', text)
    return text.lower()

def tokenize_words(text):
    words = re.split(r'\s+', text)
    return [w.strip() for w in words if w.strip()]

def tokenize_words(text):
    words = re.split(r'\s+', text)
    return [w.strip() for w in words if w.strip()]



def kmp_search(pattern, text):
    pattern_len = len(pattern)
    text_len = len(text)

    lps = [0] * pattern_len
    j = 0

    compute_lps(pattern, pattern_len, lps)

    i = 0
    while i < text_len:
        if pattern[j] == text[i]:
            i += 1
            j += 1

        if j == pattern_len:
            return i - j
        elif i < text_len and pattern[j] != text[i]:
            if j != 0:
                j = lps[j - 1]
            else:
                i += 1
    return -1

def compute_lps(pattern, pattern_len, lps):
    length = 0
    lps[0] = 0
    i = 1

    while i < pattern_len:
        if pattern[i] == pattern[length]:
            length += 1
            lps[i] = length
            i += 1
        else:
            if length != 0:
                length = lps[length - 1]
            else:
                lps[i] = 0
                i += 1

def detect_plagiarism(library_text_file, suspected_paper, threshold):
    with open(library_text_file, 'r') as file:
        library_text = file.read()

    with open(suspected_paper, 'r') as file:
        paper_text = file.read()

    library_text = preprocess(library_text)
    paper_text = preprocess(paper_text)

    library_words = tokenize_words(library_text)
    paper_words = tokenize_words(paper_text)

    matches = 0
    total_words = len(paper_words)

    for word in paper_words:
        for lib_word in library_words:
            if kmp_search(word, lib_word) != -1:
                matches += 1
                break

    similarity_percentage = (matches / total_words) * 100

    if similarity_percentage >= threshold:
        return True, similarity_percentage
    else:
        return False, similarity_percentage


def process_multiple_papers(library_text_file, threshold):
    results = []
    index = 1

    library_size = sum(1 for line in open(library_text_file, 'r') for _ in line)

    while True:
        suspected_paper = f'suspected_paper{index}.txt'

        if not os.path.exists(suspected_paper):
            break

        start_time = timeit.default_timer()
        is_plagiarism, plagiarism_percentage = detect_plagiarism(library_text_file, suspected_paper, threshold)
        elapsed_time = timeit.default_timer() - start_time

        paper_size = sum(1 for line in open(suspected_paper, 'r') for _ in line)
        size_product = library_size * paper_size
        results.append((suspected_paper, size_product, is_plagiarism, plagiarism_percentage, elapsed_time))
        print(f"{suspected_paper}: Plagiarism detected: {is_plagiarism}, Plagiarism Percentage: {plagiarism_percentage:.2f}%, Time: {elapsed_time:.5f} seconds")

        index += 1

    return results

def plot_time_complexity(results):
    size_products = [r[1] for r in results]
    times = [r[4] for r in results]

    plt.plot(size_products, times, 'ro-')
    plt.xlabel('Product of Library Size and Suspected Paper Size (characters)')
    plt.ylabel('Time Complexity (seconds)')
    plt.title('KMP Plagiarism Detection Time Complexity')
    plt.show()

library_text_file = 'library.txt'
threshold = 30

results = process_multiple_papers(library_text_file, threshold)
plot_time_complexity(results)


